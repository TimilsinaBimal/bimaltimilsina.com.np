<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Large Language Models on Bimal Timilsina</title><link>http://bimaltimilsina.com.np/categories/large-language-models/</link><description>Recent content in Large Language Models on Bimal Timilsina</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><copyright>{year}</copyright><lastBuildDate>Fri, 26 Apr 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://bimaltimilsina.com.np/categories/large-language-models/index.xml" rel="self" type="application/rss+xml"/><item><title>Demystifying Quantization: Shrinking Models for Efficient AI</title><link>http://bimaltimilsina.com.np/blog/quantization/</link><pubDate>Fri, 26 Apr 2024 00:00:00 +0000</pubDate><guid>http://bimaltimilsina.com.np/blog/quantization/</guid><description>Introduction #Large Language Models (LLMs) are revolutionizing AI research these days. Many tasks that once required complex models can now be solved in minutes with the help of LLMs.</description></item><item><title>Revolutionizing LLM Fine-Tuning:Low-Rank Adaptation (LoRA)</title><link>http://bimaltimilsina.com.np/blog/lora/</link><pubDate>Wed, 17 Apr 2024 00:00:00 +0000</pubDate><guid>http://bimaltimilsina.com.np/blog/lora/</guid><description>Introduction #Large Language Models (LLMs) and Neural Networks have revolutionized tasks like classification, summarization, and information extraction.</description></item></channel></rss>